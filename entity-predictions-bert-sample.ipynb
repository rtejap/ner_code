{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Entity extraction using BERT\n\nFull tutorial video: https://www.youtube.com/watch?v=MqQ7rqRllIc","metadata":{}},{"cell_type":"markdown","source":"## Import everything important","metadata":{}},{"cell_type":"code","source":"import joblib\nimport torch\nimport torch.nn as nn\nimport transformers\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn import preprocessing\nfrom sklearn import model_selection\n\nfrom tqdm import tqdm\nfrom transformers import AdamW\nfrom transformers import get_linear_schedule_with_warmup\nimport gc","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-20T14:24:52.045679Z","iopub.execute_input":"2023-07-20T14:24:52.046230Z","iopub.status.idle":"2023-07-20T14:24:52.958973Z","shell.execute_reply.started":"2023-07-20T14:24:52.046185Z","shell.execute_reply":"2023-07-20T14:24:52.958128Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n","output_type":"stream"}]},{"cell_type":"code","source":"import datetime\nprint(datetime.datetime.now())","metadata":{"execution":{"iopub.status.busy":"2023-07-20T14:24:52.960642Z","iopub.execute_input":"2023-07-20T14:24:52.961004Z","iopub.status.idle":"2023-07-20T14:24:52.967401Z","shell.execute_reply.started":"2023-07-20T14:24:52.960971Z","shell.execute_reply":"2023-07-20T14:24:52.966435Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"2023-07-20 14:24:52.962344\n","output_type":"stream"}]},{"cell_type":"code","source":"ner_data_path = '/kaggle/input/sample-input-raw-file/sample_input_raw_file.csv'","metadata":{"execution":{"iopub.status.busy":"2023-07-20T14:24:52.968931Z","iopub.execute_input":"2023-07-20T14:24:52.969591Z","iopub.status.idle":"2023-07-20T14:24:52.978324Z","shell.execute_reply.started":"2023-07-20T14:24:52.969551Z","shell.execute_reply":"2023-07-20T14:24:52.977580Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"ner_file = pd.read_csv(ner_data_path,sep = '\\t')\nner_file.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-20T14:24:52.979990Z","iopub.execute_input":"2023-07-20T14:24:52.980419Z","iopub.status.idle":"2023-07-20T14:24:53.000204Z","shell.execute_reply.started":"2023-07-20T14:24:52.980373Z","shell.execute_reply":"2023-07-20T14:24:52.999442Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(21, 2)"},"metadata":{}}]},{"cell_type":"code","source":"ner_file.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-07-20T14:24:53.002471Z","iopub.execute_input":"2023-07-20T14:24:53.003155Z","iopub.status.idle":"2023-07-20T14:24:53.016945Z","shell.execute_reply.started":"2023-07-20T14:24:53.003093Z","shell.execute_reply":"2023-07-20T14:24:53.015928Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   Charter_Num                         OWNER_NAME\n0            1  CK BROWN PROPERTY HOLDINGS  L.L.C\n1            2                           CK BROWN\n2            3                         TIM CHURCH\n3            4                     TRINITY CHURCH\n4            5                          BOB BAKER","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Charter_Num</th>\n      <th>OWNER_NAME</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>CK BROWN PROPERTY HOLDINGS  L.L.C</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>CK BROWN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>TIM CHURCH</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>TRINITY CHURCH</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>BOB BAKER</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"ner_file = ner_file[['Charter_Num','OWNER_NAME']]","metadata":{"execution":{"iopub.status.busy":"2023-07-20T14:24:53.021245Z","iopub.execute_input":"2023-07-20T14:24:53.021559Z","iopub.status.idle":"2023-07-20T14:24:53.026784Z","shell.execute_reply.started":"2023-07-20T14:24:53.021531Z","shell.execute_reply":"2023-07-20T14:24:53.025699Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ner_file = ner_file[:10000]\nprint(ner_file.shape)","metadata":{"execution":{"iopub.status.busy":"2023-07-20T14:24:53.031548Z","iopub.execute_input":"2023-07-20T14:24:53.032019Z","iopub.status.idle":"2023-07-20T14:24:53.037579Z","shell.execute_reply.started":"2023-07-20T14:24:53.031980Z","shell.execute_reply":"2023-07-20T14:24:53.036352Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"(21, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"ner_file.rename(columns = {'DBA_ID_f':'Charter_Num','OWNER_NAME':'Name'},inplace= True)","metadata":{"execution":{"iopub.status.busy":"2023-07-20T14:24:53.038996Z","iopub.execute_input":"2023-07-20T14:24:53.039536Z","iopub.status.idle":"2023-07-20T14:24:53.047319Z","shell.execute_reply.started":"2023-07-20T14:24:53.039497Z","shell.execute_reply":"2023-07-20T14:24:53.046187Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"ner_file.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-07-20T14:24:53.049035Z","iopub.execute_input":"2023-07-20T14:24:53.049451Z","iopub.status.idle":"2023-07-20T14:24:53.062493Z","shell.execute_reply.started":"2023-07-20T14:24:53.049413Z","shell.execute_reply":"2023-07-20T14:24:53.061319Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"   Charter_Num                               Name\n0            1  CK BROWN PROPERTY HOLDINGS  L.L.C\n1            2                           CK BROWN\n2            3                         TIM CHURCH\n3            4                     TRINITY CHURCH\n4            5                          BOB BAKER","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Charter_Num</th>\n      <th>Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>CK BROWN PROPERTY HOLDINGS  L.L.C</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>CK BROWN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>TIM CHURCH</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>TRINITY CHURCH</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>BOB BAKER</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def process_test_data(data_path):\n    df = pd.read_csv(data_path, encoding=\"latin-1\",sep = '\\t')\n    \n    df = df[['Charter_Num','OWNER_NAME']]\n    #df = df[:10000]\n    df.rename(columns = {'DBA_ID_f':'Charter_Num','OWNER_NAME':'Name'},inplace= True)\n    df['Name'].fillna('unknown',inplace= True)\n    print(df.head(5))\n    #df['sent_len'] = df['Bus_Name'].str.split().len()\n    \n    #df.loc[:, \"Sentence #\"] = df[\"Sentence #\"].fillna(method=\"ffill\")\n\n    #enc_pos = preprocessing.LabelEncoder()\n    #enc_tag = preprocessing.LabelEncoder()\n\n    #df.loc[:, \"POS\"] = enc_pos.fit_transform(df[\"POS\"])\n    #df.loc[:, \"Tag\"] = enc_tag.fit_transform(df[\"Tag\"])\n    \n    long_data_frame = pd.DataFrame([(row[1].Charter_Num,word) for row in df[['Charter_Num','Name']].iterrows()\n                         for word in row[1].Name.split()],columns= ['Charter_Num','word'])\n    long_data_frame['pos'] = 0\n    long_data_frame['tags'] = 0\n\n    #sentences = long_data_frame.groupby(['Charter_Num'])['Bus_Name'].apply(list).values\n    \n    #pos=[[0] * len(sentences)], \n    #tags=[[0] * len(sentences)]\n    \n    sentences = long_data_frame.groupby(\"Charter_Num\")[\"word\"].apply(list).values\n    pos = long_data_frame.groupby(\"Charter_Num\")[\"pos\"].apply(list).values\n    tag = long_data_frame.groupby(\"Charter_Num\")[\"tags\"].apply(list).values\n    Charter_Num_list = long_data_frame.groupby(\"Charter_Num\")[\"Charter_Num\"].apply(list).values\n    \n    return sentences, pos, tag,Charter_Num_list","metadata":{"execution":{"iopub.status.busy":"2023-07-20T14:24:53.064314Z","iopub.execute_input":"2023-07-20T14:24:53.064700Z","iopub.status.idle":"2023-07-20T14:24:53.077060Z","shell.execute_reply.started":"2023-07-20T14:24:53.064662Z","shell.execute_reply":"2023-07-20T14:24:53.076111Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#data_path = '../input/oh-formatch-v2-unknown/OH_formatch_v2_unknown.csv'\ntest_pred_sentences,test_pos,test_tag,Charter_Num_list = process_test_data(ner_data_path)","metadata":{"execution":{"iopub.status.busy":"2023-07-20T14:24:53.078922Z","iopub.execute_input":"2023-07-20T14:24:53.079332Z","iopub.status.idle":"2023-07-20T14:24:53.118468Z","shell.execute_reply.started":"2023-07-20T14:24:53.079290Z","shell.execute_reply":"2023-07-20T14:24:53.117219Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"   Charter_Num                               Name\n0            1  CK BROWN PROPERTY HOLDINGS  L.L.C\n1            2                           CK BROWN\n2            3                         TIM CHURCH\n3            4                     TRINITY CHURCH\n4            5                          BOB BAKER\n","output_type":"stream"}]},{"cell_type":"code","source":"    df = pd.read_csv(ner_data_path, encoding=\"latin-1\",sep = '\\t')\n    df = df[['Charter_Num','OWNER_NAME']]\n    #df = df[:10000]\n    df.rename(columns = {'DBA_ID_f':'Charter_Num','OWNER_NAME':'Name'},inplace= True)\n    df['Name'].fillna('unknown',inplace= True)\n    print(df.head(5))\n    #df['sent_len'] = df['Bus_Name'].str.split().len()\n    \n    #df.loc[:, \"Sentence #\"] = df[\"Sentence #\"].fillna(method=\"ffill\")\n\n    #enc_pos = preprocessing.LabelEncoder()\n    #enc_tag = preprocessing.LabelEncoder()\n\n    #df.loc[:, \"POS\"] = enc_pos.fit_transform(df[\"POS\"])\n    #df.loc[:, \"Tag\"] = enc_tag.fit_transform(df[\"Tag\"])\n    \n    long_data_frame = pd.DataFrame([(row[1].Charter_Num,word) for row in df[['Charter_Num','Name']].iterrows()\n                         for word in row[1].Name.split()],columns= ['Charter_Num','word'])\n    long_data_frame['pos'] = 0\n    long_data_frame['tags'] = 0\n","metadata":{"execution":{"iopub.status.busy":"2023-07-20T14:24:53.119834Z","iopub.execute_input":"2023-07-20T14:24:53.120184Z","iopub.status.idle":"2023-07-20T14:24:53.146083Z","shell.execute_reply.started":"2023-07-20T14:24:53.120147Z","shell.execute_reply":"2023-07-20T14:24:53.145273Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"   Charter_Num                               Name\n0            1  CK BROWN PROPERTY HOLDINGS  L.L.C\n1            2                           CK BROWN\n2            3                         TIM CHURCH\n3            4                     TRINITY CHURCH\n4            5                          BOB BAKER\n","output_type":"stream"}]},{"cell_type":"code","source":"long_data_frame","metadata":{"execution":{"iopub.status.busy":"2023-07-20T14:24:53.147414Z","iopub.execute_input":"2023-07-20T14:24:53.147782Z","iopub.status.idle":"2023-07-20T14:24:53.166780Z","shell.execute_reply.started":"2023-07-20T14:24:53.147745Z","shell.execute_reply":"2023-07-20T14:24:53.165819Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"    Charter_Num           word  pos  tags\n0             1             CK    0     0\n1             1          BROWN    0     0\n2             1       PROPERTY    0     0\n3             1       HOLDINGS    0     0\n4             1          L.L.C    0     0\n5             2             CK    0     0\n6             2          BROWN    0     0\n7             3            TIM    0     0\n8             3         CHURCH    0     0\n9             4        TRINITY    0     0\n10            4         CHURCH    0     0\n11            5            BOB    0     0\n12            5          BAKER    0     0\n13            6          BOB'S    0     0\n14            6         BAKERY    0     0\n15            7            PAM    0     0\n16            7          MASON    0     0\n17            8        ANTONIO    0     0\n18            8         FIELDS    0     0\n19            9        ANTONIO    0     0\n20            9         FIELDS    0     0\n21            9      DETAILING    0     0\n22           10        HEATHER    0     0\n23           10        DELIGHT    0     0\n24           10        STALVEY    0     0\n25           11        DELIGHT    0     0\n26           11            ICE    0     0\n27           11          CREAM    0     0\n28           12           JOHN    0     0\n29           12          SALON    0     0\n30           13         JOHN'S    0     0\n31           13          SALON    0     0\n32           14          JOHNS    0     0\n33           14          SALON    0     0\n34           15      FERNANDEZ    0     0\n35           15          SALON    0     0\n36           16         VICTOR    0     0\n37           16          SALON    0     0\n38           17           TODD    0     0\n39           17              A    0     0\n40           17          GRANT    0     0\n41           18       RESEARCH    0     0\n42           18          GRANT    0     0\n43           19         NATOYA    0     0\n44           19              A    0     0\n45           19  QUEENBOURROWS    0     0\n46           20         SHAWNA    0     0\n47           20          HEART    0     0\n48           21          LAMAR    0     0\n49           21       OLIVIIER    0     0\n50           21           LAKE    0     0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Charter_Num</th>\n      <th>word</th>\n      <th>pos</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>CK</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>BROWN</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>PROPERTY</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>HOLDINGS</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>L.L.C</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2</td>\n      <td>CK</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2</td>\n      <td>BROWN</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>3</td>\n      <td>TIM</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3</td>\n      <td>CHURCH</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>4</td>\n      <td>TRINITY</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>4</td>\n      <td>CHURCH</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>5</td>\n      <td>BOB</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>5</td>\n      <td>BAKER</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>6</td>\n      <td>BOB'S</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>6</td>\n      <td>BAKERY</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>7</td>\n      <td>PAM</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>7</td>\n      <td>MASON</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>8</td>\n      <td>ANTONIO</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>8</td>\n      <td>FIELDS</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>9</td>\n      <td>ANTONIO</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>9</td>\n      <td>FIELDS</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>9</td>\n      <td>DETAILING</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>10</td>\n      <td>HEATHER</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>10</td>\n      <td>DELIGHT</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>10</td>\n      <td>STALVEY</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>11</td>\n      <td>DELIGHT</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>11</td>\n      <td>ICE</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>11</td>\n      <td>CREAM</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>12</td>\n      <td>JOHN</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>12</td>\n      <td>SALON</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>13</td>\n      <td>JOHN'S</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>13</td>\n      <td>SALON</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>14</td>\n      <td>JOHNS</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>14</td>\n      <td>SALON</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>15</td>\n      <td>FERNANDEZ</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>15</td>\n      <td>SALON</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>16</td>\n      <td>VICTOR</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>16</td>\n      <td>SALON</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>17</td>\n      <td>TODD</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>17</td>\n      <td>A</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>17</td>\n      <td>GRANT</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>18</td>\n      <td>RESEARCH</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>18</td>\n      <td>GRANT</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>19</td>\n      <td>NATOYA</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>19</td>\n      <td>A</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>19</td>\n      <td>QUEENBOURROWS</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>20</td>\n      <td>SHAWNA</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>20</td>\n      <td>HEART</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>21</td>\n      <td>LAMAR</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>21</td>\n      <td>OLIVIIER</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>21</td>\n      <td>LAKE</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Some config","metadata":{}},{"cell_type":"code","source":"class config:\n    MAX_LEN = 128\n    TRAIN_BATCH_SIZE = 32\n    VALID_BATCH_SIZE = 8\n    EPOCHS = 3\n    BASE_MODEL_PATH = \"../input/bert-base-uncased/\"\n    MODEL_PATH = '/kaggle/input/entity-classification-model-bert/model.bin'\n    TRAINING_FILE = \"../input/entity-annotated-corpus/ner_dataset.csv\"\n    TOKENIZER = transformers.BertTokenizer.from_pretrained(\n        BASE_MODEL_PATH,\n        do_lower_case=True\n    )","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2023-07-20T14:24:53.168346Z","iopub.execute_input":"2023-07-20T14:24:53.169039Z","iopub.status.idle":"2023-07-20T14:24:53.217577Z","shell.execute_reply.started":"2023-07-20T14:24:53.168996Z","shell.execute_reply":"2023-07-20T14:24:53.216689Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Dataset","metadata":{}},{"cell_type":"code","source":"class EntityDataset:\n    def __init__(self, texts, pos, tags):\n        self.texts = texts\n        self.pos = pos\n        self.tags = tags\n    \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, item):\n        text = self.texts[item]\n        pos = self.pos[item]\n        tags = self.tags[item]\n\n        ids = []\n        target_pos = []\n        target_tag =[]\n\n        for i, s in enumerate(text):\n            inputs = config.TOKENIZER.encode(\n                s,\n                add_special_tokens=False\n            )\n            # abhishek: ab ##hi ##sh ##ek\n            input_len = len(inputs)\n            ids.extend(inputs)\n            target_pos.extend([pos[i]] * input_len)\n            target_tag.extend([tags[i]] * input_len)\n\n        ids = ids[:config.MAX_LEN - 2]\n        target_pos = target_pos[:config.MAX_LEN - 2]\n        target_tag = target_tag[:config.MAX_LEN - 2]\n\n        ids = [101] + ids + [102]\n        target_pos = [0] + target_pos + [0]\n        target_tag = [0] + target_tag + [0]\n\n        mask = [1] * len(ids)\n        token_type_ids = [0] * len(ids)\n\n        padding_len = config.MAX_LEN - len(ids)\n\n        ids = ids + ([0] * padding_len)\n        mask = mask + ([0] * padding_len)\n        token_type_ids = token_type_ids + ([0] * padding_len)\n        target_pos = target_pos + ([0] * padding_len)\n        target_tag = target_tag + ([0] * padding_len)\n\n        return {\n            \"ids\": torch.tensor(ids, dtype=torch.long),\n            \"mask\": torch.tensor(mask, dtype=torch.long),\n            \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n            \"target_pos\": torch.tensor(target_pos, dtype=torch.long),\n            \"target_tag\": torch.tensor(target_tag, dtype=torch.long),\n        }","metadata":{"execution":{"iopub.status.busy":"2023-07-20T14:24:53.219540Z","iopub.execute_input":"2023-07-20T14:24:53.219815Z","iopub.status.idle":"2023-07-20T14:24:53.238193Z","shell.execute_reply.started":"2023-07-20T14:24:53.219787Z","shell.execute_reply":"2023-07-20T14:24:53.237274Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Training and evaluation functions","metadata":{}},{"cell_type":"code","source":"def train_fn(data_loader, model, optimizer, device, scheduler):\n    model.train()\n    final_loss = 0\n    for data in tqdm(data_loader, total=len(data_loader)):\n        for k, v in data.items():\n            data[k] = v.to(device)\n        optimizer.zero_grad()\n        _, _, loss = model(**data)\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        final_loss += loss.item()\n    return final_loss / len(data_loader)\n\n\ndef eval_fn(data_loader, model, device):\n    model.eval()\n    final_loss = 0\n    for data in tqdm(data_loader, total=len(data_loader)):\n        for k, v in data.items():\n            data[k] = v.to(device)\n        _, _, loss = model(**data)\n        final_loss += loss.item()\n    return final_loss / len(data_loader)","metadata":{"execution":{"iopub.status.busy":"2023-07-20T14:24:53.239650Z","iopub.execute_input":"2023-07-20T14:24:53.240240Z","iopub.status.idle":"2023-07-20T14:24:53.253300Z","shell.execute_reply.started":"2023-07-20T14:24:53.240198Z","shell.execute_reply":"2023-07-20T14:24:53.252463Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## Loss function and model","metadata":{}},{"cell_type":"code","source":"def loss_fn(output, target, mask, num_labels):\n    lfn = nn.CrossEntropyLoss()\n    active_loss = mask.view(-1) == 1\n    active_logits = output.view(-1, num_labels)\n    active_labels = torch.where(\n        active_loss,\n        target.view(-1),\n        torch.tensor(lfn.ignore_index).type_as(target)\n    )\n    loss = lfn(active_logits, active_labels)\n    return loss\n\n\nclass EntityModel(nn.Module):\n    def __init__(self, num_tag, num_pos):\n        super(EntityModel, self).__init__()\n        self.num_tag = num_tag\n        self.num_pos = num_pos\n        self.bert = transformers.BertModel.from_pretrained(\n            config.BASE_MODEL_PATH\n        )\n        self.bert_drop_1 = nn.Dropout(0.3)\n        self.bert_drop_2 = nn.Dropout(0.3)\n        self.out_tag = nn.Linear(768, self.num_tag)\n        self.out_pos = nn.Linear(768, self.num_pos)\n    \n    def forward(\n        self, \n        ids, \n        mask, \n        token_type_ids, \n        target_pos, \n        target_tag\n    ):\n        o1, _ = self.bert(\n            ids, \n            attention_mask=mask, \n            token_type_ids=token_type_ids\n        )\n\n        bo_tag = self.bert_drop_1(o1)\n        bo_pos = self.bert_drop_2(o1)\n\n        tag = self.out_tag(bo_tag)\n        pos = self.out_pos(bo_pos)\n\n        loss_tag = loss_fn(tag, target_tag, mask, self.num_tag)\n        loss_pos = loss_fn(pos, target_pos, mask, self.num_pos)\n\n        loss = (loss_tag + loss_pos) / 2\n\n        return tag, pos, loss","metadata":{"execution":{"iopub.status.busy":"2023-07-20T14:24:53.256694Z","iopub.execute_input":"2023-07-20T14:24:53.257037Z","iopub.status.idle":"2023-07-20T14:24:53.274361Z","shell.execute_reply.started":"2023-07-20T14:24:53.257007Z","shell.execute_reply":"2023-07-20T14:24:53.273544Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## Data processing","metadata":{}},{"cell_type":"code","source":"'''\ndef process_data(data_path):\n    df = pd.read_csv(data_path, encoding=\"latin-1\")\n    df.loc[:, \"Sentence #\"] = df[\"Sentence #\"].fillna(method=\"ffill\")\n    df['Name'].fillna('unknown',inplace= True)\n\n    enc_pos = preprocessing.LabelEncoder()\n    enc_tag = preprocessing.LabelEncoder()\n\n    df.loc[:, \"POS\"] = enc_pos.fit_transform(df[\"POS\"])\n    df.loc[:, \"Tag\"] = enc_tag.fit_transform(df[\"Tag\"])\n\n    sentences = df.groupby(\"Sentence #\")[\"Word\"].apply(list).values\n    pos = df.groupby(\"Sentence #\")[\"POS\"].apply(list).values\n    tag = df.groupby(\"Sentence #\")[\"Tag\"].apply(list).values\n    return sentences, pos, tag, enc_pos, enc_tag\n'''","metadata":{"execution":{"iopub.status.busy":"2023-07-20T14:24:53.275647Z","iopub.execute_input":"2023-07-20T14:24:53.276101Z","iopub.status.idle":"2023-07-20T14:24:53.288810Z","shell.execute_reply.started":"2023-07-20T14:24:53.276068Z","shell.execute_reply":"2023-07-20T14:24:53.287953Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"'\\ndef process_data(data_path):\\n    df = pd.read_csv(data_path, encoding=\"latin-1\")\\n    df.loc[:, \"Sentence #\"] = df[\"Sentence #\"].fillna(method=\"ffill\")\\n    df[\\'Name\\'].fillna(\\'unknown\\',inplace= True)\\n\\n    enc_pos = preprocessing.LabelEncoder()\\n    enc_tag = preprocessing.LabelEncoder()\\n\\n    df.loc[:, \"POS\"] = enc_pos.fit_transform(df[\"POS\"])\\n    df.loc[:, \"Tag\"] = enc_tag.fit_transform(df[\"Tag\"])\\n\\n    sentences = df.groupby(\"Sentence #\")[\"Word\"].apply(list).values\\n    pos = df.groupby(\"Sentence #\")[\"POS\"].apply(list).values\\n    tag = df.groupby(\"Sentence #\")[\"Tag\"].apply(list).values\\n    return sentences, pos, tag, enc_pos, enc_tag\\n'"},"metadata":{}}]},{"cell_type":"code","source":"df = pd.read_csv( \"../input/entity-annotated-corpus/ner_dataset.csv\", encoding=\"latin-1\")\ndf.loc[:, \"Sentence #\"] = df[\"Sentence #\"].fillna(method=\"ffill\")\n#df = df[:10000]\n\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-20T14:24:53.290669Z","iopub.execute_input":"2023-07-20T14:24:53.291086Z","iopub.status.idle":"2023-07-20T14:24:54.027373Z","shell.execute_reply.started":"2023-07-20T14:24:53.291047Z","shell.execute_reply":"2023-07-20T14:24:54.026360Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"(1048575, 4)"},"metadata":{}}]},{"cell_type":"code","source":"df.head(15)","metadata":{"execution":{"iopub.status.busy":"2023-07-20T14:24:54.028769Z","iopub.execute_input":"2023-07-20T14:24:54.029145Z","iopub.status.idle":"2023-07-20T14:24:54.044180Z","shell.execute_reply.started":"2023-07-20T14:24:54.029110Z","shell.execute_reply":"2023-07-20T14:24:54.042903Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"     Sentence #           Word  POS    Tag\n0   Sentence: 1      Thousands  NNS      O\n1   Sentence: 1             of   IN      O\n2   Sentence: 1  demonstrators  NNS      O\n3   Sentence: 1           have  VBP      O\n4   Sentence: 1        marched  VBN      O\n5   Sentence: 1        through   IN      O\n6   Sentence: 1         London  NNP  B-geo\n7   Sentence: 1             to   TO      O\n8   Sentence: 1        protest   VB      O\n9   Sentence: 1            the   DT      O\n10  Sentence: 1            war   NN      O\n11  Sentence: 1             in   IN      O\n12  Sentence: 1           Iraq  NNP  B-geo\n13  Sentence: 1            and   CC      O\n14  Sentence: 1         demand   VB      O","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence #</th>\n      <th>Word</th>\n      <th>POS</th>\n      <th>Tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sentence: 1</td>\n      <td>Thousands</td>\n      <td>NNS</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sentence: 1</td>\n      <td>of</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Sentence: 1</td>\n      <td>demonstrators</td>\n      <td>NNS</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Sentence: 1</td>\n      <td>have</td>\n      <td>VBP</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sentence: 1</td>\n      <td>marched</td>\n      <td>VBN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Sentence: 1</td>\n      <td>through</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Sentence: 1</td>\n      <td>London</td>\n      <td>NNP</td>\n      <td>B-geo</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Sentence: 1</td>\n      <td>to</td>\n      <td>TO</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Sentence: 1</td>\n      <td>protest</td>\n      <td>VB</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Sentence: 1</td>\n      <td>the</td>\n      <td>DT</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Sentence: 1</td>\n      <td>war</td>\n      <td>NN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Sentence: 1</td>\n      <td>in</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Sentence: 1</td>\n      <td>Iraq</td>\n      <td>NNP</td>\n      <td>B-geo</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Sentence: 1</td>\n      <td>and</td>\n      <td>CC</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Sentence: 1</td>\n      <td>demand</td>\n      <td>VB</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"'''\nsentences, pos, tag, enc_pos, enc_tag = process_data(config.TRAINING_FILE)\n\nmeta_data = {\n    \"enc_pos\": enc_pos,\n    \"enc_tag\": enc_tag\n}\n\njoblib.dump(meta_data, \"meta.bin\")\n\nnum_pos = len(list(enc_pos.classes_))\nnum_tag = len(list(enc_tag.classes_))\n\n(\n    train_sentences,\n    test_sentences,\n    train_pos,\n    test_pos,\n    train_tag,\n    test_tag\n) = model_selection.train_test_split(\n    sentences, \n    pos, \n    tag, \n    random_state=42, \n    test_size=0.1\n)\n\ntrain_dataset = EntityDataset(\n    texts=train_sentences, pos=train_pos, tags=train_tag\n)\n\ntrain_data_loader = torch.utils.data.DataLoader(\n    train_dataset, batch_size=config.TRAIN_BATCH_SIZE, num_workers=4\n)\n\nvalid_dataset = EntityDataset(\n    texts=test_sentences, pos=test_pos, tags=test_tag\n)\n\nvalid_data_loader = torch.utils.data.DataLoader(\n    valid_dataset, batch_size=config.VALID_BATCH_SIZE, num_workers=1\n)\n\ndevice = torch.device(\"cuda\")\nmodel = EntityModel(num_tag=num_tag, num_pos=num_pos)\nmodel.to(device)\n\nparam_optimizer = list(model.named_parameters())\nno_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\noptimizer_parameters = [\n    {\n        \"params\": [\n            p for n, p in param_optimizer if not any(\n                nd in n for nd in no_decay\n            )\n        ],\n        \"weight_decay\": 0.001,\n    },\n    {\n        \"params\": [\n            p for n, p in param_optimizer if any(\n                nd in n for nd in no_decay\n            )\n        ],\n        \"weight_decay\": 0.0,\n    },\n]\n\nnum_train_steps = int(\n    len(train_sentences) / config.TRAIN_BATCH_SIZE * config.EPOCHS\n)\noptimizer = AdamW(optimizer_parameters, lr=3e-5)\nscheduler = get_linear_schedule_with_warmup(\n    optimizer, \n    num_warmup_steps=0, \n    num_training_steps=num_train_steps\n)\n\nbest_loss = np.inf\nfor epoch in range(config.EPOCHS):\n    train_loss = train_fn(\n        train_data_loader, \n        model, \n        optimizer, \n        device, \n        scheduler\n    )\n    test_loss = eval_fn(\n        valid_data_loader,\n        model,\n        device\n    )\n    print(f\"Train Loss = {train_loss} Valid Loss = {test_loss}\")\n    if test_loss < best_loss:\n        torch.save(model.state_dict(), config.MODEL_PATH)\n        best_loss = test_loss\n        \n'''","metadata":{"execution":{"iopub.status.busy":"2023-07-20T14:24:54.046403Z","iopub.execute_input":"2023-07-20T14:24:54.046931Z","iopub.status.idle":"2023-07-20T14:24:54.057356Z","shell.execute_reply.started":"2023-07-20T14:24:54.046890Z","shell.execute_reply":"2023-07-20T14:24:54.056367Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"'\\nsentences, pos, tag, enc_pos, enc_tag = process_data(config.TRAINING_FILE)\\n\\nmeta_data = {\\n    \"enc_pos\": enc_pos,\\n    \"enc_tag\": enc_tag\\n}\\n\\njoblib.dump(meta_data, \"meta.bin\")\\n\\nnum_pos = len(list(enc_pos.classes_))\\nnum_tag = len(list(enc_tag.classes_))\\n\\n(\\n    train_sentences,\\n    test_sentences,\\n    train_pos,\\n    test_pos,\\n    train_tag,\\n    test_tag\\n) = model_selection.train_test_split(\\n    sentences, \\n    pos, \\n    tag, \\n    random_state=42, \\n    test_size=0.1\\n)\\n\\ntrain_dataset = EntityDataset(\\n    texts=train_sentences, pos=train_pos, tags=train_tag\\n)\\n\\ntrain_data_loader = torch.utils.data.DataLoader(\\n    train_dataset, batch_size=config.TRAIN_BATCH_SIZE, num_workers=4\\n)\\n\\nvalid_dataset = EntityDataset(\\n    texts=test_sentences, pos=test_pos, tags=test_tag\\n)\\n\\nvalid_data_loader = torch.utils.data.DataLoader(\\n    valid_dataset, batch_size=config.VALID_BATCH_SIZE, num_workers=1\\n)\\n\\ndevice = torch.device(\"cuda\")\\nmodel = EntityModel(num_tag=num_tag, num_pos=num_pos)\\nmodel.to(device)\\n\\nparam_optimizer = list(model.named_parameters())\\nno_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\\noptimizer_parameters = [\\n    {\\n        \"params\": [\\n            p for n, p in param_optimizer if not any(\\n                nd in n for nd in no_decay\\n            )\\n        ],\\n        \"weight_decay\": 0.001,\\n    },\\n    {\\n        \"params\": [\\n            p for n, p in param_optimizer if any(\\n                nd in n for nd in no_decay\\n            )\\n        ],\\n        \"weight_decay\": 0.0,\\n    },\\n]\\n\\nnum_train_steps = int(\\n    len(train_sentences) / config.TRAIN_BATCH_SIZE * config.EPOCHS\\n)\\noptimizer = AdamW(optimizer_parameters, lr=3e-5)\\nscheduler = get_linear_schedule_with_warmup(\\n    optimizer, \\n    num_warmup_steps=0, \\n    num_training_steps=num_train_steps\\n)\\n\\nbest_loss = np.inf\\nfor epoch in range(config.EPOCHS):\\n    train_loss = train_fn(\\n        train_data_loader, \\n        model, \\n        optimizer, \\n        device, \\n        scheduler\\n    )\\n    test_loss = eval_fn(\\n        valid_data_loader,\\n        model,\\n        device\\n    )\\n    print(f\"Train Loss = {train_loss} Valid Loss = {test_loss}\")\\n    if test_loss < best_loss:\\n        torch.save(model.state_dict(), config.MODEL_PATH)\\n        best_loss = test_loss\\n        \\n'"},"metadata":{}}]},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"'''\nLoreto House\nArt Weeks\nRob Painter\nJacquelyn Minchew LPC\nSoleil Salon\nNancy M Service, PhD\n'''","metadata":{"execution":{"iopub.status.busy":"2023-07-20T14:24:54.059068Z","iopub.execute_input":"2023-07-20T14:24:54.059838Z","iopub.status.idle":"2023-07-20T14:24:54.070636Z","shell.execute_reply.started":"2023-07-20T14:24:54.059798Z","shell.execute_reply":"2023-07-20T14:24:54.069648Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"'\\nLoreto House\\nArt Weeks\\nRob Painter\\nJacquelyn Minchew LPC\\nSoleil Salon\\nNancy M Service, PhD\\n'"},"metadata":{}}]},{"cell_type":"code","source":"\n\nmeta_data = joblib.load(\"/kaggle/input/entity-classification-model-bert/meta.bin\")\nenc_pos = meta_data[\"enc_pos\"]\nenc_tag = meta_data[\"enc_tag\"]\n\nnum_pos = len(list(enc_pos.classes_))\nnum_tag = len(list(enc_tag.classes_))\nsentence = \"\"\"\nROSE M KENNELLY\n\"\"\"\n'''\nsentence = \"\"\"\nMr. Trump’s tweets began just moments after a Fox News report by Mike Tobin, a \nreporter for the network, about protests in Minnesota and elsewhere. \n\"\"\"\n'''\n#sentence = \"George Washington went to Washington\"\n\ntokenized_sentence = config.TOKENIZER.encode(sentence)\ninput_ids = torch.tensor([tokenized_sentence]).cuda()\ntokens = config.TOKENIZER.convert_ids_to_tokens(input_ids.to('cpu').numpy()[0])\n\n\nsentence = sentence.split()\nprint(sentence)\nprint(tokens)\nprint(tokenized_sentence)\n\ntest_dataset = EntityDataset(\n    texts=[sentence], \n    pos=[[0] * len(sentence)], \n    tags=[[0] * len(sentence)]\n)\n\ndevice = torch.device(\"cuda\")\nmodel = EntityModel(num_tag=num_tag, num_pos=num_pos)\nmodel.load_state_dict(torch.load(config.MODEL_PATH))\nmodel.to(device)\n\nwith torch.no_grad():\n    data = test_dataset[0]\n    for k, v in data.items():\n        data[k] = v.to(device).unsqueeze(0)\n    tag, pos, _ = model(**data)\n\n    print(\n        enc_tag.inverse_transform(\n            tag.argmax(2).cpu().numpy().reshape(-1)\n        )[:len(tokenized_sentence)]\n    )\n    \n    '''\n    print(\n        enc_pos.inverse_transform(\n            pos.argmax(2).cpu().numpy().reshape(-1)\n        )[:len(tokenized_sentence)]\n    )\n    '''","metadata":{"execution":{"iopub.status.busy":"2023-07-20T14:24:54.072200Z","iopub.execute_input":"2023-07-20T14:24:54.072629Z","iopub.status.idle":"2023-07-20T14:24:59.088740Z","shell.execute_reply.started":"2023-07-20T14:24:54.072591Z","shell.execute_reply":"2023-07-20T14:24:59.087720Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"['ROSE', 'M', 'KENNELLY']\n['[CLS]', 'rose', 'm', 'ken', '##nell', '##y', '[SEP]']\n[101, 3123, 1049, 6358, 9091, 2100, 102]\n['B-art' 'B-per' 'I-per' 'I-per' 'I-per' 'I-per' 'B-art']\n","output_type":"stream"}]},{"cell_type":"code","source":"model.load_state_dict(torch.load(config.MODEL_PATH))","metadata":{"execution":{"iopub.status.busy":"2023-07-20T14:24:59.090179Z","iopub.execute_input":"2023-07-20T14:24:59.090791Z","iopub.status.idle":"2023-07-20T14:24:59.329291Z","shell.execute_reply.started":"2023-07-20T14:24:59.090741Z","shell.execute_reply":"2023-07-20T14:24:59.328311Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"def ner_output(sentence):\n\n    #sentence = \"George Washington went to Washington\"\n\n    tokenized_sentence = config.TOKENIZER.encode(sentence)\n    input_ids = torch.tensor([tokenized_sentence]).cuda()\n    tokens = config.TOKENIZER.convert_ids_to_tokens(input_ids.to('cpu').numpy()[0])\n\n\n    sentence = sentence.split()\n    #print(sentence)\n    #print(tokens)\n    #print(tokenized_sentence[1:-1])\n\n    test_dataset = EntityDataset(\n        texts=[sentence], \n        pos=[[0] * len(sentence)], \n        tags=[[0] * len(sentence)]\n    )\n\n    #device = torch.device(\"cuda\")\n    #model = EntityModel(num_tag=num_tag, num_pos=num_pos)\n    #model.load_state_dict(torch.load(config.MODEL_PATH))\n    #model.to(device)\n\n    with torch.no_grad():\n        data = test_dataset[0]\n        for k, v in data.items():\n            data[k] = v.to(device).unsqueeze(0)\n        tag, pos, _ = model(**data)\n        \n        '''\n        print(\n            enc_tag.inverse_transform(\n                tag.argmax(2).cpu().numpy().reshape(-1)\n            )[:len(tokenized_sentence)]\n        )\n      '''\n    return tokens,enc_tag.inverse_transform( tag.argmax(2).cpu().numpy().reshape(-1))[:len(tokenized_sentence)]","metadata":{"execution":{"iopub.status.busy":"2023-07-20T14:24:59.330788Z","iopub.execute_input":"2023-07-20T14:24:59.331159Z","iopub.status.idle":"2023-07-20T14:24:59.342540Z","shell.execute_reply.started":"2023-07-20T14:24:59.331119Z","shell.execute_reply":"2023-07-20T14:24:59.341556Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(ner_data_path, encoding=\"latin-1\",sep = '\\t')\ndf = df = df[['Charter_Num','OWNER_NAME']]\n#df = df[:10000]\ndf.rename(columns = {'DBA_ID_f':'Charter_Num','OWNER_NAME':'Name'},inplace= True)\ndf['Name'].fillna('unknown',inplace= True)\nprint(df.head(5))\n#df = pd.read_csv(config.TRAINING_FILE, encoding=\"latin-1\",nrows = 1000)\n#df['sent_len'] = df['Bus_Name'].str.split().str.len()","metadata":{"execution":{"iopub.status.busy":"2023-07-20T14:24:59.344221Z","iopub.execute_input":"2023-07-20T14:24:59.344901Z","iopub.status.idle":"2023-07-20T14:24:59.365545Z","shell.execute_reply.started":"2023-07-20T14:24:59.344860Z","shell.execute_reply":"2023-07-20T14:24:59.363905Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"   Charter_Num                               Name\n0            1  CK BROWN PROPERTY HOLDINGS  L.L.C\n1            2                           CK BROWN\n2            3                         TIM CHURCH\n3            4                     TRINITY CHURCH\n4            5                          BOB BAKER\n","output_type":"stream"}]},{"cell_type":"code","source":"df.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-07-20T14:24:59.366854Z","iopub.execute_input":"2023-07-20T14:24:59.367221Z","iopub.status.idle":"2023-07-20T14:24:59.379556Z","shell.execute_reply.started":"2023-07-20T14:24:59.367184Z","shell.execute_reply":"2023-07-20T14:24:59.378535Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"   Charter_Num                               Name\n0            1  CK BROWN PROPERTY HOLDINGS  L.L.C\n1            2                           CK BROWN\n2            3                         TIM CHURCH\n3            4                     TRINITY CHURCH\n4            5                          BOB BAKER","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Charter_Num</th>\n      <th>Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>CK BROWN PROPERTY HOLDINGS  L.L.C</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>CK BROWN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>TIM CHURCH</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>TRINITY CHURCH</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>BOB BAKER</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"Entity_df = pd.DataFrame(test_pred_sentences)\nEntity_df.columns = ['Name_Split']\nEntity_df['Charter_Num_list'] = Charter_Num_list\nEntity_df['Charter_Num']      = Entity_df['Charter_Num_list'].apply(lambda row: row[0] )\nEntity_df #= pd.DataFrame()","metadata":{"execution":{"iopub.status.busy":"2023-07-20T14:24:59.381475Z","iopub.execute_input":"2023-07-20T14:24:59.381934Z","iopub.status.idle":"2023-07-20T14:24:59.415749Z","shell.execute_reply.started":"2023-07-20T14:24:59.381894Z","shell.execute_reply":"2023-07-20T14:24:59.414469Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"                                Name_Split Charter_Num_list  Charter_Num\n0   [CK, BROWN, PROPERTY, HOLDINGS, L.L.C]  [1, 1, 1, 1, 1]            1\n1                              [CK, BROWN]           [2, 2]            2\n2                            [TIM, CHURCH]           [3, 3]            3\n3                        [TRINITY, CHURCH]           [4, 4]            4\n4                             [BOB, BAKER]           [5, 5]            5\n5                          [BOB'S, BAKERY]           [6, 6]            6\n6                             [PAM, MASON]           [7, 7]            7\n7                        [ANTONIO, FIELDS]           [8, 8]            8\n8             [ANTONIO, FIELDS, DETAILING]        [9, 9, 9]            9\n9              [HEATHER, DELIGHT, STALVEY]     [10, 10, 10]           10\n10                   [DELIGHT, ICE, CREAM]     [11, 11, 11]           11\n11                           [JOHN, SALON]         [12, 12]           12\n12                         [JOHN'S, SALON]         [13, 13]           13\n13                          [JOHNS, SALON]         [14, 14]           14\n14                      [FERNANDEZ, SALON]         [15, 15]           15\n15                         [VICTOR, SALON]         [16, 16]           16\n16                        [TODD, A, GRANT]     [17, 17, 17]           17\n17                       [RESEARCH, GRANT]         [18, 18]           18\n18              [NATOYA, A, QUEENBOURROWS]     [19, 19, 19]           19\n19                         [SHAWNA, HEART]         [20, 20]           20\n20                 [LAMAR, OLIVIIER, LAKE]     [21, 21, 21]           21","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name_Split</th>\n      <th>Charter_Num_list</th>\n      <th>Charter_Num</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[CK, BROWN, PROPERTY, HOLDINGS, L.L.C]</td>\n      <td>[1, 1, 1, 1, 1]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[CK, BROWN]</td>\n      <td>[2, 2]</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[TIM, CHURCH]</td>\n      <td>[3, 3]</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[TRINITY, CHURCH]</td>\n      <td>[4, 4]</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[BOB, BAKER]</td>\n      <td>[5, 5]</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>[BOB'S, BAKERY]</td>\n      <td>[6, 6]</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>[PAM, MASON]</td>\n      <td>[7, 7]</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>[ANTONIO, FIELDS]</td>\n      <td>[8, 8]</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>[ANTONIO, FIELDS, DETAILING]</td>\n      <td>[9, 9, 9]</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>[HEATHER, DELIGHT, STALVEY]</td>\n      <td>[10, 10, 10]</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>[DELIGHT, ICE, CREAM]</td>\n      <td>[11, 11, 11]</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>[JOHN, SALON]</td>\n      <td>[12, 12]</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>[JOHN'S, SALON]</td>\n      <td>[13, 13]</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>[JOHNS, SALON]</td>\n      <td>[14, 14]</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>[FERNANDEZ, SALON]</td>\n      <td>[15, 15]</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>[VICTOR, SALON]</td>\n      <td>[16, 16]</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>[TODD, A, GRANT]</td>\n      <td>[17, 17, 17]</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>[RESEARCH, GRANT]</td>\n      <td>[18, 18]</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>[NATOYA, A, QUEENBOURROWS]</td>\n      <td>[19, 19, 19]</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>[SHAWNA, HEART]</td>\n      <td>[20, 20]</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>[LAMAR, OLIVIIER, LAKE]</td>\n      <td>[21, 21, 21]</td>\n      <td>21</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_dataset = EntityDataset(\n    texts=test_pred_sentences, pos=test_pos, tags=test_tag\n)\n\ntest_data_loader = torch.utils.data.DataLoader(\n    test_dataset, batch_size=128, num_workers=1\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-20T14:24:59.417372Z","iopub.execute_input":"2023-07-20T14:24:59.417787Z","iopub.status.idle":"2023-07-20T14:24:59.425108Z","shell.execute_reply.started":"2023-07-20T14:24:59.417746Z","shell.execute_reply":"2023-07-20T14:24:59.424177Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    tag_list= []\n    for data in tqdm(test_data_loader, total=len(test_data_loader)):\n            \n            for k, v in data.items():\n                data[k] = v.to(device)\n            tag, pos, _ = model(**data)\n            tag_list.append(tag)\n            \ntag_all = torch.cat(tag_list)","metadata":{"execution":{"iopub.status.busy":"2023-07-20T14:24:59.426985Z","iopub.execute_input":"2023-07-20T14:24:59.427568Z","iopub.status.idle":"2023-07-20T14:24:59.631819Z","shell.execute_reply.started":"2023-07-20T14:24:59.427517Z","shell.execute_reply":"2023-07-20T14:24:59.630683Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00,  5.30it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"df.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-07-20T14:24:59.633742Z","iopub.execute_input":"2023-07-20T14:24:59.634126Z","iopub.status.idle":"2023-07-20T14:24:59.646418Z","shell.execute_reply.started":"2023-07-20T14:24:59.634084Z","shell.execute_reply":"2023-07-20T14:24:59.645357Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"   Charter_Num                               Name\n0            1  CK BROWN PROPERTY HOLDINGS  L.L.C\n1            2                           CK BROWN\n2            3                         TIM CHURCH\n3            4                     TRINITY CHURCH\n4            5                          BOB BAKER","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Charter_Num</th>\n      <th>Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>CK BROWN PROPERTY HOLDINGS  L.L.C</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>CK BROWN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>TIM CHURCH</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>TRINITY CHURCH</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>BOB BAKER</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df['tokenized_sent'] = df['Name'].apply(lambda row:  config.TOKENIZER.encode(row))","metadata":{"execution":{"iopub.status.busy":"2023-07-20T14:24:59.647948Z","iopub.execute_input":"2023-07-20T14:24:59.648611Z","iopub.status.idle":"2023-07-20T14:24:59.660698Z","shell.execute_reply.started":"2023-07-20T14:24:59.648571Z","shell.execute_reply":"2023-07-20T14:24:59.659896Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"count = 0\nenc_tag_list= []\nfor i in tag_all:\n    \n    enc_tag_list.append(enc_tag.inverse_transform(\n            i[None,:,:].argmax(2).cpu().numpy().reshape(-1)[:len(df.loc[:,'tokenized_sent'][count])]\n        ))\n    count = count+1","metadata":{"execution":{"iopub.status.busy":"2023-07-20T14:24:59.662420Z","iopub.execute_input":"2023-07-20T14:24:59.662799Z","iopub.status.idle":"2023-07-20T14:24:59.682275Z","shell.execute_reply.started":"2023-07-20T14:24:59.662760Z","shell.execute_reply":"2023-07-20T14:24:59.681209Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"Entity_df['enc_tag'] = enc_tag_list","metadata":{"execution":{"iopub.status.busy":"2023-07-20T14:24:59.683853Z","iopub.execute_input":"2023-07-20T14:24:59.684540Z","iopub.status.idle":"2023-07-20T14:24:59.690620Z","shell.execute_reply.started":"2023-07-20T14:24:59.684493Z","shell.execute_reply":"2023-07-20T14:24:59.689573Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"Entity_df = pd.merge(Entity_df,df,how = 'inner')\nEntity_df","metadata":{"execution":{"iopub.status.busy":"2023-07-20T14:24:59.692164Z","iopub.execute_input":"2023-07-20T14:24:59.692866Z","iopub.status.idle":"2023-07-20T14:24:59.760619Z","shell.execute_reply.started":"2023-07-20T14:24:59.692819Z","shell.execute_reply":"2023-07-20T14:24:59.759780Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"                                Name_Split Charter_Num_list  Charter_Num  \\\n0   [CK, BROWN, PROPERTY, HOLDINGS, L.L.C]  [1, 1, 1, 1, 1]            1   \n1                              [CK, BROWN]           [2, 2]            2   \n2                            [TIM, CHURCH]           [3, 3]            3   \n3                        [TRINITY, CHURCH]           [4, 4]            4   \n4                             [BOB, BAKER]           [5, 5]            5   \n5                          [BOB'S, BAKERY]           [6, 6]            6   \n6                             [PAM, MASON]           [7, 7]            7   \n7                        [ANTONIO, FIELDS]           [8, 8]            8   \n8             [ANTONIO, FIELDS, DETAILING]        [9, 9, 9]            9   \n9              [HEATHER, DELIGHT, STALVEY]     [10, 10, 10]           10   \n10                   [DELIGHT, ICE, CREAM]     [11, 11, 11]           11   \n11                           [JOHN, SALON]         [12, 12]           12   \n12                         [JOHN'S, SALON]         [13, 13]           13   \n13                          [JOHNS, SALON]         [14, 14]           14   \n14                      [FERNANDEZ, SALON]         [15, 15]           15   \n15                         [VICTOR, SALON]         [16, 16]           16   \n16                        [TODD, A, GRANT]     [17, 17, 17]           17   \n17                       [RESEARCH, GRANT]         [18, 18]           18   \n18              [NATOYA, A, QUEENBOURROWS]     [19, 19, 19]           19   \n19                         [SHAWNA, HEART]         [20, 20]           20   \n20                 [LAMAR, OLIVIIER, LAKE]     [21, 21, 21]           21   \n\n                                              enc_tag  \\\n0   [B-art, B-org, I-org, I-org, I-org, I-org, I-o...   \n1                        [B-art, B-per, I-per, B-art]   \n2                        [B-art, B-per, I-per, B-art]   \n3                        [B-art, B-org, I-org, B-art]   \n4                        [B-art, B-per, I-per, B-art]   \n5                      [B-art, B-per, O, O, O, B-art]   \n6                        [B-art, B-per, I-per, B-art]   \n7                        [B-art, B-per, I-per, B-art]   \n8                     [B-art, B-per, I-per, O, B-art]   \n9   [B-art, B-per, I-per, I-per, I-per, I-per, B-art]   \n10                            [B-art, O, O, O, B-art]   \n11                       [B-art, B-per, I-per, B-art]   \n12                     [B-art, B-per, O, O, O, B-art]   \n13                       [B-art, B-per, I-org, B-art]   \n14                       [B-art, B-per, I-org, B-art]   \n15                       [B-art, B-per, I-per, B-art]   \n16                [B-art, B-per, I-per, I-per, B-art]   \n17                               [B-art, O, O, B-art]   \n18        [B-art, B-per, B-per, O, O, O, O, O, B-art]   \n19                [B-art, B-per, B-per, I-per, B-art]   \n20  [B-art, B-per, I-per, I-org, I-org, I-org, I-g...   \n\n                                 Name  \\\n0   CK BROWN PROPERTY HOLDINGS  L.L.C   \n1                            CK BROWN   \n2                          TIM CHURCH   \n3                      TRINITY CHURCH   \n4                           BOB BAKER   \n5                        BOB'S BAKERY   \n6                           PAM MASON   \n7                      ANTONIO FIELDS   \n8            ANTONIO FIELDS DETAILING   \n9             HEATHER DELIGHT STALVEY   \n10                  DELIGHT ICE CREAM   \n11                         JOHN SALON   \n12                       JOHN'S SALON   \n13                        JOHNS SALON   \n14                    FERNANDEZ SALON   \n15                       VICTOR SALON   \n16                       TODD A GRANT   \n17                     RESEARCH GRANT   \n18             NATOYA A QUEENBOURROWS   \n19                      SHAWNA  HEART   \n20                LAMAR OLIVIIER LAKE   \n\n                                       tokenized_sent  \n0   [101, 23616, 2829, 3200, 9583, 1048, 1012, 104...  \n1                             [101, 23616, 2829, 102]  \n2                              [101, 5199, 2277, 102]  \n3                              [101, 7124, 2277, 102]  \n4                              [101, 3960, 6243, 102]  \n5                 [101, 3960, 1005, 1055, 18112, 102]  \n6                             [101, 14089, 6701, 102]  \n7                              [101, 4980, 4249, 102]  \n8                       [101, 4980, 4249, 17555, 102]  \n9          [101, 9533, 12208, 2358, 2389, 12417, 102]  \n10                      [101, 12208, 3256, 6949, 102]  \n11                            [101, 2198, 11090, 102]  \n12                [101, 2198, 1005, 1055, 11090, 102]  \n13                           [101, 11545, 11090, 102]  \n14                           [101, 12023, 11090, 102]  \n15                            [101, 5125, 11090, 102]  \n16                       [101, 6927, 1037, 3946, 102]  \n17                             [101, 2470, 3946, 102]  \n18  [101, 10079, 3148, 1037, 3035, 25127, 10524, 2...  \n19                      [101, 13218, 2050, 2540, 102]  \n20  [101, 19756, 19330, 12848, 6137, 2121, 2697, 102]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name_Split</th>\n      <th>Charter_Num_list</th>\n      <th>Charter_Num</th>\n      <th>enc_tag</th>\n      <th>Name</th>\n      <th>tokenized_sent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[CK, BROWN, PROPERTY, HOLDINGS, L.L.C]</td>\n      <td>[1, 1, 1, 1, 1]</td>\n      <td>1</td>\n      <td>[B-art, B-org, I-org, I-org, I-org, I-org, I-o...</td>\n      <td>CK BROWN PROPERTY HOLDINGS  L.L.C</td>\n      <td>[101, 23616, 2829, 3200, 9583, 1048, 1012, 104...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[CK, BROWN]</td>\n      <td>[2, 2]</td>\n      <td>2</td>\n      <td>[B-art, B-per, I-per, B-art]</td>\n      <td>CK BROWN</td>\n      <td>[101, 23616, 2829, 102]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[TIM, CHURCH]</td>\n      <td>[3, 3]</td>\n      <td>3</td>\n      <td>[B-art, B-per, I-per, B-art]</td>\n      <td>TIM CHURCH</td>\n      <td>[101, 5199, 2277, 102]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[TRINITY, CHURCH]</td>\n      <td>[4, 4]</td>\n      <td>4</td>\n      <td>[B-art, B-org, I-org, B-art]</td>\n      <td>TRINITY CHURCH</td>\n      <td>[101, 7124, 2277, 102]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[BOB, BAKER]</td>\n      <td>[5, 5]</td>\n      <td>5</td>\n      <td>[B-art, B-per, I-per, B-art]</td>\n      <td>BOB BAKER</td>\n      <td>[101, 3960, 6243, 102]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>[BOB'S, BAKERY]</td>\n      <td>[6, 6]</td>\n      <td>6</td>\n      <td>[B-art, B-per, O, O, O, B-art]</td>\n      <td>BOB'S BAKERY</td>\n      <td>[101, 3960, 1005, 1055, 18112, 102]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>[PAM, MASON]</td>\n      <td>[7, 7]</td>\n      <td>7</td>\n      <td>[B-art, B-per, I-per, B-art]</td>\n      <td>PAM MASON</td>\n      <td>[101, 14089, 6701, 102]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>[ANTONIO, FIELDS]</td>\n      <td>[8, 8]</td>\n      <td>8</td>\n      <td>[B-art, B-per, I-per, B-art]</td>\n      <td>ANTONIO FIELDS</td>\n      <td>[101, 4980, 4249, 102]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>[ANTONIO, FIELDS, DETAILING]</td>\n      <td>[9, 9, 9]</td>\n      <td>9</td>\n      <td>[B-art, B-per, I-per, O, B-art]</td>\n      <td>ANTONIO FIELDS DETAILING</td>\n      <td>[101, 4980, 4249, 17555, 102]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>[HEATHER, DELIGHT, STALVEY]</td>\n      <td>[10, 10, 10]</td>\n      <td>10</td>\n      <td>[B-art, B-per, I-per, I-per, I-per, I-per, B-art]</td>\n      <td>HEATHER DELIGHT STALVEY</td>\n      <td>[101, 9533, 12208, 2358, 2389, 12417, 102]</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>[DELIGHT, ICE, CREAM]</td>\n      <td>[11, 11, 11]</td>\n      <td>11</td>\n      <td>[B-art, O, O, O, B-art]</td>\n      <td>DELIGHT ICE CREAM</td>\n      <td>[101, 12208, 3256, 6949, 102]</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>[JOHN, SALON]</td>\n      <td>[12, 12]</td>\n      <td>12</td>\n      <td>[B-art, B-per, I-per, B-art]</td>\n      <td>JOHN SALON</td>\n      <td>[101, 2198, 11090, 102]</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>[JOHN'S, SALON]</td>\n      <td>[13, 13]</td>\n      <td>13</td>\n      <td>[B-art, B-per, O, O, O, B-art]</td>\n      <td>JOHN'S SALON</td>\n      <td>[101, 2198, 1005, 1055, 11090, 102]</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>[JOHNS, SALON]</td>\n      <td>[14, 14]</td>\n      <td>14</td>\n      <td>[B-art, B-per, I-org, B-art]</td>\n      <td>JOHNS SALON</td>\n      <td>[101, 11545, 11090, 102]</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>[FERNANDEZ, SALON]</td>\n      <td>[15, 15]</td>\n      <td>15</td>\n      <td>[B-art, B-per, I-org, B-art]</td>\n      <td>FERNANDEZ SALON</td>\n      <td>[101, 12023, 11090, 102]</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>[VICTOR, SALON]</td>\n      <td>[16, 16]</td>\n      <td>16</td>\n      <td>[B-art, B-per, I-per, B-art]</td>\n      <td>VICTOR SALON</td>\n      <td>[101, 5125, 11090, 102]</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>[TODD, A, GRANT]</td>\n      <td>[17, 17, 17]</td>\n      <td>17</td>\n      <td>[B-art, B-per, I-per, I-per, B-art]</td>\n      <td>TODD A GRANT</td>\n      <td>[101, 6927, 1037, 3946, 102]</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>[RESEARCH, GRANT]</td>\n      <td>[18, 18]</td>\n      <td>18</td>\n      <td>[B-art, O, O, B-art]</td>\n      <td>RESEARCH GRANT</td>\n      <td>[101, 2470, 3946, 102]</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>[NATOYA, A, QUEENBOURROWS]</td>\n      <td>[19, 19, 19]</td>\n      <td>19</td>\n      <td>[B-art, B-per, B-per, O, O, O, O, O, B-art]</td>\n      <td>NATOYA A QUEENBOURROWS</td>\n      <td>[101, 10079, 3148, 1037, 3035, 25127, 10524, 2...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>[SHAWNA, HEART]</td>\n      <td>[20, 20]</td>\n      <td>20</td>\n      <td>[B-art, B-per, B-per, I-per, B-art]</td>\n      <td>SHAWNA  HEART</td>\n      <td>[101, 13218, 2050, 2540, 102]</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>[LAMAR, OLIVIIER, LAKE]</td>\n      <td>[21, 21, 21]</td>\n      <td>21</td>\n      <td>[B-art, B-per, I-per, I-org, I-org, I-org, I-g...</td>\n      <td>LAMAR OLIVIIER LAKE</td>\n      <td>[101, 19756, 19330, 12848, 6137, 2121, 2697, 102]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"Entity_df.to_csv('Entity_predictions_BERT_sample.csv',index= False)","metadata":{"execution":{"iopub.status.busy":"2023-07-20T14:24:59.762589Z","iopub.execute_input":"2023-07-20T14:24:59.762862Z","iopub.status.idle":"2023-07-20T14:24:59.996969Z","shell.execute_reply.started":"2023-07-20T14:24:59.762835Z","shell.execute_reply":"2023-07-20T14:24:59.996046Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"import datetime\nprint(datetime.datetime.now())","metadata":{"execution":{"iopub.status.busy":"2023-07-20T14:24:59.998342Z","iopub.execute_input":"2023-07-20T14:24:59.998700Z","iopub.status.idle":"2023-07-20T14:25:00.005050Z","shell.execute_reply.started":"2023-07-20T14:24:59.998660Z","shell.execute_reply":"2023-07-20T14:25:00.004121Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"2023-07-20 14:25:00.000018\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}